groups:
  - name: Windows_Alerts
    rules:
      - alert: InstanceDown
        expr: up{job="services"} < 1
        for: 5m

      - alert: WindowsServerCollectorError
        expr: windows_exporter_collector_success == 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: Windows Server collector Error (instance {{ $labels.instance }})
          description: "Collector {{ $labels.collector }} was not successful\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

      - alert: WindowsServerServiceStatus
        expr: windows_service_status{status="ok"} != 1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: Windows Server service Status (instance {{ $labels.instance }})
          description: "Windows Service state is not OK\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"


      - alert: WindowsServerCpuUsage
        expr: 100 - (avg by (instance) (rate(windows_cpu_time_total{mode="idle"}[2m])) * 100) > 80
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Windows Server CPU Usage (instance {{ $labels.instance }})
          description: "CPU Usage is more than 80%\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

      - alert: WindowsServerMemoryUsage
        expr: 100 - ((windows_os_physical_memory_free_bytes / windows_cs_physical_memory_bytes) * 100) > 90
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Windows Server memory Usage (instance {{ $labels.instance }})
          description: "Memory usage is more than 90%\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

      - alert: WindowsServerDiskSpaceUsage
        expr: 100.0 - 100 * ((windows_logical_disk_free_bytes / 1024 / 1024 ) / (windows_logical_disk_size_bytes / 1024 / 1024)) > 90
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: Windows Server disk Space Usage (instance {{ $labels.instance }})
          description: "Disk usage is more than 80%\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

  - name: LinuxAlerts
    rules:
      - alert: HostOutOfMemory
        expr: node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 10
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Host out of memory (instance {{ $labels.instance }})
          description: "Node memory is filling up (< 10% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

      - alert: HostMemoryUnderMemoryPressure
        expr: rate(node_vmstat_pgmajfault[1m]) > 1000
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Host memory under memory pressure (instance {{ $labels.instance }})
          description: "The node is under heavy memory pressure. High rate of major page faults\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

      - alert: HostUnusualNetworkThroughputIn
        expr: sum by (instance) (rate(node_network_receive_bytes_total[2m])) / 1024 / 1024 > 100
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: Host unusual network throughput in (instance {{ $labels.instance }})
          description: "Host network interfaces are probably receiving too much data (> 100 MB/s)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

      - alert: HostUnusualNetworkThroughputOut
        expr: sum by (instance) (rate(node_network_transmit_bytes_total[2m])) / 1024 / 1024 > 100
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: Host unusual network throughput out (instance {{ $labels.instance }})
          description: "Host network interfaces are probably sending too much data (> 100 MB/s)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

      - alert: HostUnusualDiskReadRate
        expr: sum by (instance) (rate(node_disk_read_bytes_total[2m])) / 1024 / 1024 > 50
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: Host unusual disk read rate (instance {{ $labels.instance }})
          description: "Disk is probably reading too much data (> 50 MB/s)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

      - alert: HostUnusualDiskWriteRate
        expr: sum by (instance) (rate(node_disk_written_bytes_total[2m])) / 1024 / 1024 > 50
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Host unusual disk write rate (instance {{ $labels.instance }})
          description: "Disk is probably writing too much data (> 50 MB/s)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

      - alert: HostOutOfDiskSpace
        expr: (node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 10 and ON (instance, device, mountpoint) node_filesystem_readonly == 0
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Host out of disk space (instance {{ $labels.instance }})
          description: "Disk is almost full (< 10% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

      - alert: HostDiskWillFillIn24Hours
        expr: (node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 10 and ON (instance, device, mountpoint) predict_linear(node_filesystem_avail_bytes{fstype!~"tmpfs"}[1h], 24 * 3600) < 0 and ON (instance, device, mountpoint) node_filesystem_readonly == 0
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Host disk will fill in 24 hours (instance {{ $labels.instance }})
          description: "Filesystem is predicted to run out of space within the next 24 hours at current write rate\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

      - alert: HostOutOfInodes
        expr: node_filesystem_files_free{mountpoint ="/rootfs"} / node_filesystem_files{mountpoint="/rootfs"} * 100 < 10 and ON (instance, device, mountpoint) node_filesystem_readonly{mountpoint="/rootfs"} == 0
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Host out of inodes (instance {{ $labels.instance }})
          description: "Disk is almost running out of available inodes (< 10% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

      - alert: HostInodesWillFillIn24Hours
        expr: node_filesystem_files_free{mountpoint ="/rootfs"} / node_filesystem_files{mountpoint="/rootfs"} * 100 < 10 and predict_linear(node_filesystem_files_free{mountpoint="/rootfs"}[1h], 24 * 3600) < 0 and ON (instance, device, mountpoint) node_filesystem_readonly{mountpoint="/rootfs"} == 0
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Host inodes will fill in 24 hours (instance {{ $labels.instance }})
          description: "Filesystem is predicted to run out of inodes within the next 24 hours at current write rate\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

      - alert: HostUnusualDiskReadLatency
        expr: rate(node_disk_read_time_seconds_total[1m]) / rate(node_disk_reads_completed_total[1m]) > 0.1 and rate(node_disk_reads_completed_total[1m]) > 0
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Host unusual disk read latency (instance {{ $labels.instance }})
          description: "Disk latency is growing (read operations > 100ms)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

      - alert: HostUnusualDiskWriteLatency
        expr: rate(node_disk_write_time_seconds_total[1m]) / rate(node_disk_writes_completed_total[1m]) > 0.1 and rate(node_disk_writes_completed_total[1m]) > 0
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Host unusual disk write latency (instance {{ $labels.instance }})
          description: "Disk latency is growing (write operations > 100ms)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

      - alert: HostHighCpuLoad
        expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[2m])) * 100) > 80
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Host high CPU load (instance {{ $labels.instance }})
          description: "CPU load is > 80%\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

      - alert: HostCpuStealNoisyNeighbor
        expr: avg by(instance) (rate(node_cpu_seconds_total{mode="steal"}[5m])) * 100 > 10
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Host CPU steal noisy neighbor (instance {{ $labels.instance }})
          description: "CPU steal is > 10%. A noisy neighbor is killing VM performances or a spot instance may be out of credit.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

      - alert: HostCpuHighIowait
        expr: avg by (instance) (rate(node_cpu_seconds_total{mode="iowait"}[5m])) * 100 > 5
        for: 0m
        labels:
          severity: warning
        annotations:
          summary: Host CPU high iowait (instance {{ $labels.instance }})
          description: "CPU iowait > 5%. A high iowait means that you are disk or network bound.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

      - alert: HostContextSwitching
        expr: (rate(node_context_switches_total[5m])) / (count without(cpu, mode) (node_cpu_seconds_total{mode="idle"})) > 1000
        for: 0m
        labels:
          severity: warning
        annotations:
          summary: Host context switching (instance {{ $labels.instance }})
          description: "Context switching is growing on node (> 1000 / s)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

      - alert: HostSwapIsFillingUp
        expr: (1 - (node_memory_SwapFree_bytes / node_memory_SwapTotal_bytes)) * 100 > 80
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Host swap is filling up (instance {{ $labels.instance }})
          description: "Swap is filling up (>80%)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

      - alert: HostNetworkBondDegraded
        expr: (node_bonding_active - node_bonding_slaves) != 0
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: Host Network Bond Degraded (instance {{ $labels.instance }})
          description: "Bond \"{{ $labels.device }}\" degraded on \"{{ $labels.instance }}\".\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

  - name: SNMP Hpe server
    rules:
    - alert: snmp_server_timeout
      expr: avg_over_time(up{job="monitor_hardware"}[30m]) < 0.5
      for: 20m
      labels:
        group: v_hardware
        type: device
        severity: critical
      annotations:
        summary: "SNMP timeout"
        description: "Server {{ $labels.instance }} of job {{ $labels.job }} has been query timeout"
        value: "{{ $value }}"

    - alert: snmp_hpe_physical_disk_failed
      expr: cpqDaPhyDrvLocationString{job="monitor_hardware"} *on(cpqDaPhyDrvIndex,instance) group_left() (cpqDaPhyDrvStatus != 2)
      for: 5m
      labels:
        group: v_hardware
        type: device
        severity: critical
      annotations:
        summary: "Server physical disk failed"
        description: "Physical Disk {{ $labels.cpqDaPhyDrvLocationString }} on Hpe server {{ $labels.instance }} has been failed"
        value: "{{ $value }}"

    - alert: snmp_hpe_memory_failed
      expr: cpqHeResMem2ModuleHwLocation{job="monitor_hardware"} *on(cpqHeResMem2Module,instance) group_left() (cpqHeResMem2ModuleStatus != 2 and cpqHeResMem2ModuleStatus != 4 and cpqHeResMem2ModuleStatus != 1)
      for: 5m
      labels:
        group: v_hardware
        type: device
        severity: critical
      annotations:
        summary: "Server memory failed"
        description: "Memory {{ $labels.cpqHeResMem2ModuleHwLocation }} on Hpe server {{ $labels.instance }} has been failed"
        value: "{{ $value }}"

    - alert: snmp_hpe_power_failed
      expr: cpqHeFltTolPowerSupplySerialNumber{job="monitor_hardware"} *on(cpqHeFltTolPowerSupplyBay,instance) group_left()(cpqHeFltTolPowerSupplyStatus != 1)
      for: 5m
      labels:
        group: v_hardware
        type: device
        severity: critical
      annotations:
        summary: "Server power failed"
        description: "Power {{ $labels.cpqHeFltTolPowerSupplySerialNumber }} on Hpe server {{ $labels.instance }} has been failed"
        value: "{{ $value }}"

    - alert: snmp_hpe_CPU_failed
      expr: cpqSeCpuName{job="monitor_hardware"} *on(cpqSeCpuUnitIndex,instance) group_left() (cpqSeCpuStatus != 2)
      for: 5m
      labels:
        group: v_hardware
        type: device
        severity: critical
      annotations:
        summary: "Server cpu failed"
        description: "CPU {{ $labels.cpqSeCpuName }} on Hpe server {{ $labels.instance }} has been failed"
        value: "{{ $value }}"

    - alert: snmp_hpe_CRC_failed
      expr: cpqNicIfPhysAdapterName{job="monitor_hardware"} *on(cpqNicIfPhysAdapterIndex,instance) group_left() (delta(cpqNicIfPhysAdapterFCSErrors[5m]) > 150)
      for: 5m
      labels:
        group: v_hardware
        type: device
        severity: critical
      annotations:
        summary: "Server CRC failed"
        description: "Port {{ $labels.cpqNicIfPhysAdapterName }} on Hpe server {{ $labels.instance }} has CRC errors"
        value: "{{ $value }}"

    - alert: snmp_hpe_temperature_sensor_failed
      expr: cpqHeTemperatureCondition{job="monitor_hardware"} != 2
      for: 5m
      labels:
        group: v_hardware
        type: device
        severity: critical
      annotations:
        summary: "Server temperature sensor failed"
        description: "Temperature sensor chassis {{ $labels.cpqHeTemperatureChassis }}-{{ $labels.cpqHeTemperatureIndex }} on Hpe server {{ $labels.instance }} has been failed"
        value: "{{ $value }}"

    - alert: snmp_hpe_fan_failed
      expr: (cpqHeFltTolFanCondition{job="monitor_hardware"} != 2) and (cpqHeFltTolFanCondition{job="monitor_hardware"} != 1)
      for: 5m
      labels:
        group: v_hardware
        type: device
        severity: critical
      annotations:
        summary: "Server fan failed"
        description: "Fan on Hpe server {{ $labels.instance }} has been failed"
        value: "{{ $value }}"

  - name: SNMP cisco switch
    rules:
    - alert: snmp_switch_timeout
      expr: avg_over_time(up{job="cisco_switch"}[30m]) < 0.5
      for: 20m
      labels:
        group: v_hardware
        type: device
        severity: critical
      annotations:
        summary: "SNMP timeout"
        description: "Switch {{ $labels.instance }} of job {{ $labels.job }} has been query timeout"
        value: "{{ $value }}"

    - alert: snmp_switch_interface_link_status_DOWN
      expr: (ifAdminStatus{device="cisco"}) *on(ifIndex,instance) group_left(ifAdminStatus) (ifAdminStatus == 2 and ifOperStatus == 2) and ifIndex{ifName!~"Vl1|Fa0"}
      for: 5m
      labels:
        group: v_hardware
        severity: critical
      annotations:
        summary: "Switch interface down"
        description: "Interface {{ $labels.ifDescr }} on {{ $labels.instance }} has DOWN more than 2 minutes."
        value: "{{ $value }}"

    - alert: snmp_switch_high_CPU_load
      expr: cpmCPUTotal5min{job="cisco_switch"} > 75
      for: 5m
      labels:
        group: v_hardware
        severity: critical
      annotations:
        summary: "Switch high CPU load "
        description: "Switch {{ $labels.instance }} CPU load over 75%"
        value: "{{ $value }}"

    - alert: snmp_switch_high_memory
      expr: 100 - (ciscoMemoryPoolFree{ciscoMemoryPoolType="1"}/(ciscoMemoryPoolFree{ciscoMemoryPoolType="1"} + ciscoMemoryPoolUsed{ciscoMemoryPoolType="1"})) * 100 > 75
      for: 5m
      labels:
        group: v_hardware
        severity: critical
      annotations:
        summary: "Switch high memory"
        description: "Switch {{ $labels.instance }} memrory used over 75%  "
        value: "{{ $value }}"
